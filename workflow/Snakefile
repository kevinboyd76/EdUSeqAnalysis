configfile: "config/config.yml"

##################################################################
##                    Define input functions                    ##
##################################################################

import pandas as pd

# Read the samples.csv file
samples_table = pd.read_csv("config/samples.csv")

# Validate the CSV file
assert samples_table["sample"].notna().all(), "Missing values in 'sample' column."
assert samples_table["Merged"].notna().all(), "Missing values in 'Merged' column."

# Combine all valid sample and merged group names
all_samples = list(samples_table["sample"]) + list(samples_table["Merged"].unique())
all_samples = list(set(all_samples))  # Remove duplicates

# Separate treatment and control samples based on the sampleType column
treatment_samples = samples_table[samples_table["sampleType"] == "treatment"]["sample"].tolist()
control_samples = samples_table[samples_table["sampleType"] == "control"]["sample"].tolist()

# Input function for FASTQ files
def fq_dict_from_sample(wildcards):
    if wildcards.sample in samples_table["sample"].values:
        # Handle individual samples
        row = samples_table[samples_table["sample"] == wildcards.sample].iloc[0]
        return {"fq1": row["fastq1"], "fq2": row["fastq2"]}
    elif wildcards.sample in samples_table["Merged"].values:
        # Handle merged groups
        rows = samples_table[samples_table["Merged"] == wildcards.sample]
        return {
            "fq1": [row["fastq1"] for _, row in rows.iterrows()],
            "fq2": [row["fastq2"] for _, row in rows.iterrows()]
        }
    else:
        raise ValueError(f"Sample {wildcards.sample} not found in the samples table.")

##################################################################
##                          Rule All                            ##
##################################################################

rule all:
    input:
        # Merged FASTQ files
        expand("results/merged/{sample}_R1.fastq.gz", sample=samples_table["Merged"].unique()),
        expand("results/merged/{sample}_R2.fastq.gz", sample=samples_table["Merged"].unique()),
        # Trimming results for all samples
        expand("results/trimmed/{sample}_trimmed_R1.fastq.gz", sample=all_samples),
        # Aligned BAM files for all samples
        expand("results/aligned/{sample}.bam", sample=all_samples),
        # SAM files and flagstat outputs
        expand("results/aligned/{sample}.sam", sample=all_samples),
        expand("results/aligned/{sample}_flagstat.txt", sample=all_samples)

##################################################################
##                    Rule: Merge FASTQ Files                   ##
##################################################################

rule merge_fastqs:
    input:
        fq1=lambda wildcards: [
            row["fastq1"] for _, row in samples_table[samples_table["Merged"] == wildcards.sample].iterrows()
        ],
        fq2=lambda wildcards: [
            row["fastq2"] for _, row in samples_table[samples_table["Merged"] == wildcards.sample].iterrows()
        ]
    output:
        merged_fq1="results/merged/{sample}_R1.fastq.gz",
        merged_fq2="results/merged/{sample}_R2.fastq.gz"
    log:
        "results/logs/snakelogs/merge_fastqs.{sample}.log"
    shell:
        """
        zcat {input.fq1} | gzip > {output.merged_fq1}
        zcat {input.fq2} | gzip > {output.merged_fq2}
        """

##################################################################
##                    Rule: Trim Reads with fastp               ##
##################################################################

rule trim_reads_with_fastp:
    input:
        unpack(fq_dict_from_sample)
    output:
        trimmed1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        trimmed2="results/trimmed/{sample}_trimmed_R2.fastq.gz",
        fastp_report="results/qc/fastp_reports/{sample}.html",
        fastp_json="results/qc/fastp_reports/{sample}.json"
    envmodules:
        config["fastp"]
    log:
        "results/logs/snakelogs/trim_reads_with_fastp.{sample}.log"
    shell:
        """
        fastp -i {input.fq1} -I {input.fq2} -o {output.trimmed1} -O {output.trimmed2} \
              -h {output.fastp_report} --json {output.fastp_json} -R "{wildcards.sample}" -w 8
        """

##################################################################
##                    Rule: Align Reads with BWA-MEM            ##
##################################################################

rule align_reads_with_bwamem:
    input:
        R1="results/trimmed/{sample}_trimmed_R1.fastq.gz",
        R2="results/trimmed/{sample}_trimmed_R2.fastq.gz"
    params:
        genome=config["bwa_genome"],
        blacklist=config["blacklistFile"]
    output:
        bam="results/aligned/{sample}.bam",
        bai="results/aligned/{sample}.bam.bai"
    envmodules:
        config["bwamem2"],
        config["samtools"],
        config["bedtools"]
    log:
        "results/logs/snakelogs/align_reads_with_bwamem.{sample}.log"
    shell:
        """
        bwa-mem2 mem -M -t 12 {params.genome} {input.R1} {input.R2} | \
        samtools view -b - | \
        bedtools intersect -v -abam - -b {params.blacklist} | \
        samtools sort -@ 12 -o {output.bam} && \
        samtools index -@ 12 {output.bam}
        """

##################################################################
##                    Rule: Generate SAM and Flagstat           ##
##################################################################

rule align_stats_gen_sam:
    input:
        bam="results/aligned/{sample}.bam"
    output:
        sam="results/aligned/{sample}.sam",
        stats="results/aligned/{sample}_flagstat.txt"
    envmodules:
        config["samtools"]
    log:
        "results/logs/snakelogs/align_stats_gen_sam.{sample}.log"
    shell:
        """
        samtools view -h -o {output.sam} {input.bam} && \
        samtools flagstat {input.bam} > {output.stats}
        """
